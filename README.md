# Advanced Cache (advCache)
Highâ€‘load inâ€‘memory HTTP cache & reverseâ€‘proxy for Go. Designed for low latency, **hundreds of thousands RPS**.

> Built around *sharded maps*, *LRU + TinyLFU admission*, *background refresh*, and a *passive/active upstream cluster* â€” with a hot path that avoids allocations and locks.

---

## âœ¨ Highlights
- **Sharded map (~2k shards)** with perâ€‘shard LRU lists and a global shard balancer for proportional eviction.
- **Admission = TinyLFU + Doorkeeper (+ Countâ€‘Min Sketch):** keep frequent keys, reject noise.
- **Writeâ€‘through / Readâ€‘through** with **background revalidation** (TTL, Î²â€‘staggering, scanâ€‘rate, rateâ€‘limit).
- **Backend cluster** with passive error tracking, throttling, quarantine/cure, and fanâ€‘in request pattern.
- **Compression pools** (gzip/brotli), zeroâ€‘copy header handling, and careful buffer reuse.
- **Perâ€‘shard dump & restore** with CRC32 and version rotation (optional GZIP).
- **Fasthttp server** + small REST surface + Prometheus/VictoriaMetrics metrics.
- **K8sâ€‘friendly** liveness, graceful shutdown, configurable GOMAXPROCS (automaxprocs on zero value).

---

## ğŸ§­ Repository map (components)
> Overview â€” follow the links to dive deeper.

### 1) Storage
- `pkg/storage/lru/*`
    - **`storage.go`** â€“ orchestration; wires LFU admission, refresher, dumper, evictor.
    - **`evictor.go`** â€“ periodic proportional eviction: selects the heaviest shards (â‰ˆ top 17%) and evicts from their tail.
    - **`refresher.go`** â€“ background revalidation engine (TTL, *beta* coefficient, scan & backend rate limits).
    - **`dumper.go`** â€“ perâ€‘shard dumps to `dump_dir/dump_name-<shard>-<ts>.dump[.gz]` with CRC32, **max_versions** rotation; load restores last complete snapshot.
    - **`balancer.go`** â€“ tracks perâ€‘shard memory and maintains an **ordered shard list** (most loaded first) for fast, fair eviction.
- `pkg/storage/lfu/*`
    - **`tiny_lfu.go`** â€“ **TinyLFU** admission with two countâ€‘min sketches (**curr, prev**) and a **doorkeeper** Bloomâ€‘like filter; rotation periodically halves history.
- `pkg/storage/map/*`
    - **`map.go`** â€“ **sharded map**. Constants show an intent for ~**2047 active shards** + **1 collision shard** (2048 total).
    - **`shard.go`** â€“ perâ€‘shard operations (Get/Set/Del), *Weight()* accounting, releaser pools.

### 2) HTTP layer
- `pkg/http/server/*` â€“ thin Fasthttp server with router + middleware chain. Tuned buffer sizes, disabled normalizations, minimal parsing for speed.
- `internal/cache/api/*`
    - **`cache.go`** â€“ main GET handler: cache lookup â†’ upstream on miss/error â†’ writeâ€‘through on 200.
    - **`on_off.go`** â€“ feature switch: `/cache/on`, `/cache/off` (simple toggles, JSON).
    - **`clear.go`** â€“ twoâ€‘step clear with shortâ€‘lived token (defense against accidental wipe).
- `pkg/http/responder` â€“ writes from cached *Entry* or raw *fasthttp.Response* with zeroâ€‘copy headers; sets `Last-Revalidated`.
- `pkg/http/header` â€“ small helpers (pooled RFC1123 formatting).

### 3) Modeling & pools
- `pkg/model/entry.go` â€“ the **Entry**: key derivation (path + selected query + selected headers), request/response payload storage, weight accounting, CASâ€‘like lifecycle helpers.
- `pkg/pools/*` â€“ slice pools for hotâ€‘path temporary structures (e.g., key/value header views).

### 4) Upstream cluster
- `pkg/upstream/*`
    - **`backend.go`** â€“ perâ€‘backend HTTP client (tls, dialer, timeouts) with **rate limiting**; builds upstream URIs from request.
    - **`slot.go`** â€“ backend slot state machine (**healthy â†’ sick â†’ dead**), hotâ€‘path counters, throttling window and step, quarantine.
    - **`cluster.go`** â€“ cluster manager: builds slots from `cfg.Cluster.Backends`, initial probes; used fan-in pattern of healthy backends rate limiters ("select" implements pseudo-random). Has two policies: `deny` and `await` to control the behavior of requests in case no backend is ready (all are busy).
    - **`monitor.go`** â€“ workers: **minute errorâ€‘rate scan** (6â€‘s ticks), slowâ€‘start, throttling/unthrottling, sick/dead idlers handling; emits cluster health snapshots.

### 5) Metrics & ops
- `pkg/prometheus/metrics/*` â€“ VictoriaMetrics adapter + `/metrics` controller; counters for hits/misses/errors/panics, cache length, RPS, avg duration.
- `pkg/k8s/probe/liveness/*` â€“ liveness service & HTTP endpoint integration.
- `pkg/gc` â€“ periodic GC trigger (configurable).

### 6) Utilities
- `pkg/sort/key_value.go` â€“ allocationâ€‘free insertion sort for `[][2][]byte` (query/header canonicalization).
- `pkg/bytes/cmp.go` â€“ shortâ€‘circuit eq + XXH3â€‘assisted equality for large slices.
- `pkg/list/*` â€“ generic doublyâ€‘linked list used by shard balancer.

### 7) Entrypoint & configuration
- `cmd/main.go` â€“ boot sequence: config â†’ upstreams â†’ storage â†’ HTTP â†’ probes â†’ metrics â†’ GC â†’ graceful shutdown.
- `pkg/config/config.go` â€“ YAML config loader, hot reload friendly; exposes typed subtrees for cache, upstream, storage, eviction, refresh, metrics, k8s.

---

## âš™ï¸ Configuration (YAML)
See [`advCache.cfg.yaml`](./advCache.cfg.yaml) and `advCache.cfg.local.yaml` for a runnable setup.

```yaml
cache:
  env: "dev"                 # dev|prod|test
  enabled: true
  runtime:
    gomaxprocs: 12           # auto-tuned via automaxprocs at startup too
  api:
    name: "advCache"
    port: "8020"

  # Upstream cluster
  upstream:
    cluster:
      backends:
        - id: "b1"
          enabled: true
          scheme: "http"
          host: "127.0.0.1:8080"
          rate: 800          # per-backend limit (req/s)
          slow_start: 10s
          probe_interval: 2s
        - id: "b2"
          enabled: true
          scheme: "http"
          host: "127.0.0.1:8081"
          rate: 800          # per-backend limit (req/s)
          slow_start: 10s
          probe_interval: 2s
        - id: "b3"
          enabled: true
          scheme: "https"
          host: "example.backend.com"
          rate: 800          # per-backend limit (req/s)
          slow_start: 10s
          probe_interval: 2s

  # Cache I/O
  data:
    enabled: true
    dump:
      enabled: true
      dump_dir: "public/dump"
      dump_name: "cache.dump"
      crc32_control_sum: true
      max_versions: 3
      gzip: false
    mock:                # for local stress
      enabled: false
      length: 1000000

  # Memory budget
  storage:
    size: 34359738368    # 32 GiB

  eviction:
    enabled: true
    threshold: 0.95      # start eviction at 95% of budget

  refresh:
    enabled: true
    ttl: "24h"
    rate: 8              # backend RPS cap for refreshes
    scan_rate: 10000     # entries/s to scan
    beta: 0.4            # stagger factor to avoid herd
    coefficient: 0.5     # start refresh at 50% of TTL

  forceGC:
    enabled: true
    interval: "10s"

  metrics:
    # exposed at /metrics (VictoriaMetrics compatible)
    enabled: true

  # Key canonicalization (example)
  keys:
    cache_key:
      query:
        - project[id]
        - domain
        - language
        - choice
        - timezone
      headers:
        - Accept-Encoding
    cache_value:
      headers:
        - Content-Type
        - Content-Encoding
        - Cache-Control
        - Vary
```

> **Notes**
> - Shards: 2048.
> - Dump files are perâ€‘shard; **load** picks the latest complete timestamp batch across shards.

---

## â–¶ï¸ Quick start
```bash
# Build
go build -o advCache cmd/main.go

# Run with the default config
./advCache -c ./advancedCache.cfg.yaml

# Or run in Docker
docker build -t advcache .
docker run --rm -p 8020:8020 -v $PWD/public/dump:/app/public/dump advcache
```

**HTTP surface:**
- `GET /{any:*}` â€“ main cached endpoint (path + selected query + headers form the key).
- `GET /cache/on` / `GET /cache/off` â€“ toggle cache without restart.
- `GET /metrics` â€“ Prometheus/VictoriaMetrics.
- `GET /cache/clear` â€“ twoâ€‘step clear (request token, then confirm with the token).

---

## ğŸ—ï¸ Architecture
```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  fasthttp    â”‚
         â”‚   router     â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚  GET /{any}
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Cache Controller   â”‚â”€â”€â”€metrics/hits/miss/err
        â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚hit      â”‚miss
            â”‚         â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”     â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Storage   â”‚     â”‚  fetch       â”‚  Upstream Cluster   â”‚
   â”‚ (LRU/TLFU) â”‚â—„â”€â”€â”€â”€â”˜â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  slots + workers    â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ evict (heavy shards)               â”‚ throttle/quarantine
          â”‚ dump/load                          â”‚ errorâ€‘rate scan
          â–¼                                    â–¼
      perâ€‘shard lists                     backend clients
```

**Hot path facts**
- Lookups are perâ€‘shard with short critical sections; payload copies are avoided.
- Keys are formed from selected query & headers; canonicalization uses inâ€‘place sort to avoid allocs.
- Response write uses header copy **once** and direct body set.

---

## ğŸ“ˆ Benchmarks (current)
- Storage: **Read â‰ˆ 40 ns/op**, **Write â‰ˆ 50 ns/op** (benchmarks provided).
- Stress cache: **1,000,000** random elements Ã— **4 KiB** each (**~4.5 GiB**) at **~200,000 RPS** on a 6â€‘CPU box.
- Stress proxy: **1,000,000** random elements Ã— **4 KiB** each (**~4.5 GiB**) at **~100,000 RPS** on a 6â€‘CPU box (the same cache app. has been used as a backend in stress tests).

---

## âœ… Testing & benchmarking
- Unit tests: storage map, list, TinyLFU; storage integration.
- Benchmarks: TinyLFU; list; (extend with storage hotâ€‘path ops).
- Suggested additions:
    - Endâ€‘toâ€‘end readâ€‘through/writeâ€‘through with mocked upstreams (race + bench).
    - Dump/load fuzz (corrupt/partial files; CRC failures; version rotation).
    - Cluster lifecycle under fault injection: spikes, 5xx bursts, timeouts, slowâ€‘start, idle revival.
    - Allocation budget tests (`-run=^$ -bench=... -benchmem` + `GODEBUG=madvdontneed=1`).
    - Concurrency/race tests on `Entry` lifecycle (Acquire/Release/Remove), shard eviction under pressure.

---

## ğŸ”§ Production tuning
- **GOMAXPROCS**: leave `automaxprocs` on; pin containers with CPU quotas.
- **Memory budget**: watch `cache.storage.size`, start eviction at 90â€“95%.
- **Logging**: keep hot path silent; keep structured logs in workers only.
- **Compression**: pool writers/readers; prefer preâ€‘compressed bodies from upstream when possible.
- **Probes**: add readiness probe (not just liveness) if you gate traffic behind priming loads.
- **Sysctls**: bump `somaxconn`, ephemeral ports, and file descriptors for high fanâ€‘out.

---

## ğŸ§ª Observability (VictoriaMetrics/Prometheus)
Key series (names from `pkg/prometheus/metrics/keyword`):
- `adv_cache_hits_total`, `adv_cache_misses_total`, `adv_cache_errors_total`, `adv_cache_panicked_total`
- `adv_cache_proxied_total` â€“ upstream fallbacks
- `adv_cache_map_length` â€“ items in cache
- `adv_cache_avg_duration_seconds` â€“ rolling average of request duration
- Custom cluster gauges: healthy/sick/dead backends

---

## ğŸ“¦ Build & deploy
- **Dockerfile** provided; consider enabling `GODEBUG=gctrace=1` in staging to size memory budgets.
- Run under a reverse proxy or as a sidecar; health probes ready.
- Minimal external deps: Fasthttp, VictoriaMetrics, XXH3, automaxprocs.

---

## ğŸ¤ Contributing
PRs are welcome. Please include:
- Short description and rationale.
- Benchmarks (`-benchmem`) and allocations deltas for hotâ€‘path changes.
- Race tests for concurrencyâ€‘sensitive changes.

---

## ğŸ“„ License
MIT â€” see [LICENSE](./LICENSE).

---

## Maintainer
**Borislav Glazunov** â€” Telegram: `@glbrslv`, Gmail: glazunov2142@gmail.com. Issues and discussions welcome.
